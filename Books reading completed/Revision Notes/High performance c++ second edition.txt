Chaper 1 : Introduction
	1.  The zero-overhead principle
		What you don't use, you don't pay for
		What you do use, you couldn't hand code any better
		
2. Essential C++ Techniques
	1. A forwarding reference
		auto&& is called a forwarding reference (also referred to as a universal reference)
		Forwarding references will, just like const references, extend the lifetime of a temporary
		auto&& allows us to mutate objects it references, temporaries included
	2.  std::experimental::propagate_const
		To prevent modification under the const function, using pointer
		Note that propagate_const only applies to pointers, and pointer-like classes such as std:shared_ptr and std::unique_ptr, but not std::function
			#include <experimental/propagate_const> &
			std::experimental::propagate_const<int*> ptr_ = nullptr;
	3.  auto b = std::move(a); // Tell the compiler to move the resource into b
	4. Rule of 3:  The copy-constructor, copy-assignment, and destructor, all or none
	5. Note, how ref member can be copy or moved 
		
		private: 
		  size_t size_{0}; 
		  float* ptr_{nullptr};
		  int& ref_;
	
		// 1. Copy constructor 
		Buffer::Buffer(const Buffer& other) : size_{other.size_}, ref_{other.ref_} { 
		  ptr_ = new float[size_]; 
		  std::copy(other.ptr_, other.ptr_ + size_, ptr_); 
		} 
		// 2. Copy assignment 
		auto& Buffer::operator=(const Buffer& other) {
		  delete [] ptr_;
		  ptr_ = new float[other.size_];
		  size_ = other.size_;
		  std::copy(other.ptr_, other.ptr_ + size_, ptr_);
		  return *this;
		}
		// 4. Move constructor
		Buffer::Buffer(Buffer&& other) noexcept : size_{other.size_}, ptr_{other.ptr_}, , ref_{other.ref_} {
		  other.ptr_ = nullptr;
		  other.size_ = 0;
		}
		// 5. Move assignment
		auto& Buffer::operator=(Buffer&& other) noexcept {
		  ptr_ = other.ptr_;
		  size_ = other.size_;
		  other.ptr_ = nullptr;
		  other.size_ = 0;
		  return *this;
		}
	6. Do not forget to mark your move-constructors and move-assignment operators as noexcept (unless they might throw an exception, of course). Not marking them noexcept prevents standard library containers and algorithms from utilizing them, instead resorting to using a regular copy/assignment under certain conditions.
	7. Named variables and rvalues
		1.  the compiler moves an object when the object can be categorized as an rvalue.
		2.  rvalue it is just an object that is not tied to a named variable
		3.  We make a variable an rvalue by using std::move()
		4.  str is declared const and therefore is not allowed to mutate:
        const auto str = get_ok();
		button.set_title(std::move(str));  // copy-assigned
	8. Default move semantics and the rule of zero
		1. Writing an empty destructor can prevent the compiler from implementing certain optimizations
		2. However, if we remove the destructor or declare the destructor default, the compiler optimizes std::copy() to utilize memmove() instead of a loop:
		3. Using std::swap we can implement move constructor, but for move assignment it may not be always correct case or expected
		4.  member function that has the && modifier will only be considered by overload resolution if the object is an rvalue
			ex. auto func() && {}
			//usage
			auto a = Foo{}; 
			a.func();            // Doesn't compile, 'a' is not an rvalue 
			std::move(a).func(); // Compiles 
			Foo{}.func();        // Compiles
		5. return std::move(x);  // Don't, RVO is prevented
		 This usage of std::move() prevents the compiler from using return value optimization (RVO)
		6. C++ has no built-in support for contracts yet, but there is ongoing work to add it to future versions of C++. Use a library such as Boost.Contract.
		7. static_assert() or the assert() macro from the <cassert> header.
		8. the only way to signal errors from constructors is by using exceptions.
		9. A function marked with noexcept makes it possible for the compiler to generate faster code in some cases
		10. The size of the binary program is increased even if exceptions are not being thrown.
	9. function call operator of a lambda is const by default, so we explicitly need to specify that the lambda can mutate its members by using the mutable keyword
	10. auto lambda = +[](int result, const char* str) {} This way, the lambda is converted into a regular function pointer.
	11. Lambdas, the compiler has the ability to inline the function call; The flexible design of std::function make it nearly impossible for the compiler to inline a function wrapped in
	12. If a std::function use local buffer optimization, if not possible then use heap, it use memory to store the captured variables.
	13. Lambdas internally uses type erasure 
	14. Generic lambda
		// Using auto
		auto x = [](auto v) { return v + 1; };
		// Using typename
		auto y = []<typename Val>(Val v) { return v + 1; };
		
		
3 Analyzing and Measuring Performance
	1.  std::midpoint use ful for binary search
	2. Latency/response time: time between the request and the response of an operation
	3.  A task is said to be CPU bound if it would run faster if the CPU were faster. It's said to be I/O bound if it would run faster by making the I/O faster.
	4.  Intel provides a powerful tool called VTune, which can be used for monitoring performance counters. FreeBSD offers pmcstat. macOS comes with DTrace and Xcode Instruments. Microsoft Visual Studio provides support for collecting CPU counters on Windows.
	5. Instrumentation profilers, adding code in code for measurement
	6. steady_clock is monotonic, which means that it will never decrease between two consecutive calls to clock_type::now(). System clock can be adjsuted.
	7. Sampling profilers, some logic may not be running at that moment
	8. Pitfalls of microbenchmarking
		1.  compiler might optimize isolated code differently compared to how it is optimized in the full program
		2. Unrealistic test data can have an impact on branch prediction when running the benchmark.
		3. Results between multiple measurements might vary because of factors such as frequency scaling, cache pollution, and the scheduling of other processes.
		4.  tested online on the page http://quick-bench.com without the need for any installation.
		5.  benchmark::DoNotOptimize()
		BENCHMARK(bm_linear_search)->RangeMultiplier(2)->Range(64, 256);
		BENCHMARK_MAIN();
		6.  let the framework estimate the time complexity of our functions. This can be done by providing the input size to the state object using the SetComplexityN() function
	
4 Data Structures
	1.  potentially already residesÂ in the cache will make your program faster. This is known as temporal locality
	2.  spatial locality, benifit of accessing data located near some other data.
	3. Constantly wiping out the cache lines is cache thrashing
	4. Person(Person&& other) {         // Will be copied 
	Person(Person&& other) noexcept { // Will be moved
	due to strong exception safety
	5.  std::vector uses std::move_if_noexcept in order to determine whether the object should be copied or moved.
	6. C++ 20,  std::erase() and std::erase_if(), is combination of erase-remove idiom
	7.  std::list is a doubly linked list and for singly linked list  std::forward_list
	8. Always use the specialized functions, such as contains() and empty(), instead of using count() > 0 or size() == 0. The specialized functions are guaranteed to be the most efficient ones.
	9. Hash function using boost
	
    #include <boost/functional/hash.hpp>
	auto person_hash = [](const Person& person) { 
	  auto seed = size_t{0};
	  boost::hash_combine(seed, person.name()); 
	  boost::hash_combine(seed, person.age()); 
	  return seed;
	};
		
    using Set = std::unordered_set<Person,
	decltype(person_hash),                                decltype(person_eq)>;
	10. Priority queue syntax
	auto queue = std::priority_queue<Hit, std::vector<Hit>,                                    decltype(cmp)>{cmp};
	11. Before C++20, the recommended way was to use lower_bound(), since it only returns the first matching element. Now, with C++20 and the introduction of contains(), we can express our intent more clearly and also be sure that the library will provide us  with the most efficient implementation when we only want to check for existence of an element:
	12. By using parallel arrays, we simply split the large structures into smaller types(better for searching) ,  But instead of using pointers to relate objects, we store the smaller structures in separate arrays of equal size. The smaller objects in the different arrays that share the same index form the complete original object.
	
5 Algorithms
	1. 