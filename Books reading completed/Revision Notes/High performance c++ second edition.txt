Chaper 1 : Introduction
	1.  The zero-overhead principle
		What you don't use, you don't pay for
		What you do use, you couldn't hand code any better
		
2. Essential C++ Techniques
	1. A forwarding reference
		auto&& is called a forwarding reference (also referred to as a universal reference)
		Forwarding references will, just like const references, extend the lifetime of a temporary
		auto&& allows us to mutate objects it references, temporaries included
	2.  std::experimental::propagate_const
		To prevent modification under the const function, using pointer
		Note that propagate_const only applies to pointers, and pointer-like classes such as std:shared_ptr and std::unique_ptr, but not std::function
			#include <experimental/propagate_const> &
			std::experimental::propagate_const<int*> ptr_ = nullptr;
	3.  auto b = std::move(a); // Tell the compiler to move the resource into b
	4. Rule of 3:  The copy-constructor, copy-assignment, and destructor, all or none
	5. Note, how ref member can be copy or moved 
		
		private: 
		  size_t size_{0}; 
		  float* ptr_{nullptr};
		  int& ref_;
	
		// 1. Copy constructor 
		Buffer::Buffer(const Buffer& other) : size_{other.size_}, ref_{other.ref_} { 
		  ptr_ = new float[size_]; 
		  std::copy(other.ptr_, other.ptr_ + size_, ptr_); 
		} 
		// 2. Copy assignment 
		auto& Buffer::operator=(const Buffer& other) {
		  delete [] ptr_;
		  ptr_ = new float[other.size_];
		  size_ = other.size_;
		  std::copy(other.ptr_, other.ptr_ + size_, ptr_);
		  return *this;
		}
		// 4. Move constructor
		Buffer::Buffer(Buffer&& other) noexcept : size_{other.size_}, ptr_{other.ptr_}, , ref_{other.ref_} {
		  other.ptr_ = nullptr;
		  other.size_ = 0;
		}
		// 5. Move assignment
		auto& Buffer::operator=(Buffer&& other) noexcept {
		  ptr_ = other.ptr_;
		  size_ = other.size_;
		  other.ptr_ = nullptr;
		  other.size_ = 0;
		  return *this;
		}
	6. Do not forget to mark your move-constructors and move-assignment operators as noexcept (unless they might throw an exception, of course). Not marking them noexcept prevents standard library containers and algorithms from utilizing them, instead resorting to using a regular copy/assignment under certain conditions.
	7. Named variables and rvalues
		1.  the compiler moves an object when the object can be categorized as an rvalue.
		2.  rvalue it is just an object that is not tied to a named variable
		3.  We make a variable an rvalue by using std::move()
		4.  str is declared const and therefore is not allowed to mutate:
        const auto str = get_ok();
		button.set_title(std::move(str));  // copy-assigned
	8. Default move semantics and the rule of zero
		1. Writing an empty destructor can prevent the compiler from implementing certain optimizations
		2. However, if we remove the destructor or declare the destructor default, the compiler optimizes std::copy() to utilize memmove() instead of a loop:
		3. Using std::swap we can implement move constructor, but for move assignment it may not be always correct case or expected
		4.  member function that has the && modifier will only be considered by overload resolution if the object is an rvalue
			ex. auto func() && {}
			//usage
			auto a = Foo{}; 
			a.func();            // Doesn't compile, 'a' is not an rvalue 
			std::move(a).func(); // Compiles 
			Foo{}.func();        // Compiles
		5. return std::move(x);  // Don't, RVO is prevented
		 This usage of std::move() prevents the compiler from using return value optimization (RVO)
		6. C++ has no built-in support for contracts yet, but there is ongoing work to add it to future versions of C++. Use a library such as Boost.Contract.
		7. static_assert() or the assert() macro from the <cassert> header.
		8. the only way to signal errors from constructors is by using exceptions.
		9. A function marked with noexcept makes it possible for the compiler to generate faster code in some cases
		10. The size of the binary program is increased even if exceptions are not being thrown.
	9. function call operator of a lambda is const by default, so we explicitly need to specify that the lambda can mutate its members by using the mutable keyword
	10. auto lambda = +[](int result, const char* str) {} This way, the lambda is converted into a regular function pointer.
	11. Lambdas, the compiler has the ability to inline the function call; The flexible design of std::function make it nearly impossible for the compiler to inline a function wrapped in
	12. If a std::function use local buffer optimization, if not possible then use heap, it use memory to store the captured variables.
	13. Lambdas internally uses type erasure 
	14. Generic lambda
		// Using auto
		auto x = [](auto v) { return v + 1; };
		// Using typename
		auto y = []<typename Val>(Val v) { return v + 1; };
		
		
3 Analyzing and Measuring Performance
	1.  std::midpoint use ful for binary search
	2. Latency/response time: time between the request and the response of an operation
	3.  A task is said to be CPU bound if it would run faster if the CPU were faster. It's said to be I/O bound if it would run faster by making the I/O faster.
	4.  Intel provides a powerful tool called VTune, which can be used for monitoring performance counters. FreeBSD offers pmcstat. macOS comes with DTrace and Xcode Instruments. Microsoft Visual Studio provides support for collecting CPU counters on Windows.
	5. Instrumentation profilers, adding code in code for measurement
	6. steady_clock is monotonic, which means that it will never decrease between two consecutive calls to clock_type::now(). System clock can be adjsuted.
	7. Sampling profilers, some logic may not be running at that moment
	8. Pitfalls of microbenchmarking
		1.  compiler might optimize isolated code differently compared to how it is optimized in the full program
		2. Unrealistic test data can have an impact on branch prediction when running the benchmark.
		3. Results between multiple measurements might vary because of factors such as frequency scaling, cache pollution, and the scheduling of other processes.
		4.  tested online on the page http://quick-bench.com without the need for any installation.
		5.  benchmark::DoNotOptimize()
		BENCHMARK(bm_linear_search)->RangeMultiplier(2)->Range(64, 256);
		BENCHMARK_MAIN();
		6.  let the framework estimate the time complexity of our functions. This can be done by providing the input size to the state object using the SetComplexityN() function
	
4 Data Structures
	1.  potentially already resides in the cache will make your program faster. This is known as temporal locality
	2.  spatial locality, benifit of accessing data located near some other data.
	3. Constantly wiping out the cache lines is cache thrashing
	4. Person(Person&& other) {         // Will be copied 
	Person(Person&& other) noexcept { // Will be moved
	due to strong exception safety
	5.  std::vector uses std::move_if_noexcept in order to determine whether the object should be copied or moved.
	6. C++ 20,  std::erase() and std::erase_if(), is combination of erase-remove idiom
	7.  std::list is a doubly linked list and for singly linked list  std::forward_list
	8. Always use the specialized functions, such as contains() and empty(), instead of using count() > 0 or size() == 0. The specialized functions are guaranteed to be the most efficient ones.
	9. Hash function using boost
	
    #include <boost/functional/hash.hpp>
	auto person_hash = [](const Person& person) { 
	  auto seed = size_t{0};
	  boost::hash_combine(seed, person.name()); 
	  boost::hash_combine(seed, person.age()); 
	  return seed;
	};
		
    using Set = std::unordered_set<Person,
	decltype(person_hash),                                decltype(person_eq)>;
	10. Priority queue syntax
	auto queue = std::priority_queue<Hit, std::vector<Hit>,                                    decltype(cmp)>{cmp};
	11. Before C++20, the recommended way was to use lower_bound(), since it only returns the first matching element. Now, with C++20 and the introduction of contains(), we can express our intent more clearly and also be sure that the library will provide us  with the most efficient implementation when we only want to check for existence of an element:
	12. By using parallel arrays, we simply split the large structures into smaller types(better for searching) ,  But instead of using pointers to relate objects, we store the smaller structures in separate arrays of equal size. The smaller objects in the different arrays that share the same index form the complete original object.
	
5 Algorithms
	1. std::ranges::for_each, std::ranges::transform, std::ranges::fill(v, -1), std::ranges::generate(v, std::rand); std::ranges::sort,  std::ranges::find
	2. If we know that the collection is already sorted, we can use one of the binary search algorithms: binary_search(), equal_range(), upper_bound(), or lower_bound()
	3. std::clamp(v, lo, hi); If the value of v is within [lo, hi], returns v; otherwise returns the nearest boundary.
	4. minmax()
	5. Type with below constraint can be called as range
		template<class T>
		concept range = requires(T& t) {
		  ranges::begin(t);
		  ranges::end(t);
		};
	6.  A range with identical iterator and sentinel types fulfills the concept of std::ranges::common_range
	7. Iterator arithmetic 
		std::next
		std::pre
		std::advance
	8. std::contiguous_iterator: The same as random access iterators, but also guarantees that the underlying data is a contiguous block of memory, such as std::string, std::vector, std::array, std::span, and the (rarely used) std::valarray
	9.  std::remove() or std::unique() do not actually remove elements from a container (despite their names). Rather, it moves the elements
	10. How insert iterator works in c++,  insert iterators call the container's insert() member function to add new elements.
	auto dst_vec = std::back_inserter(squared_vec);
	std::ranges::transform(v, dst_vec, square_func);
	11. Three way operator
    auto operator<=>(const Flower& f) const = default; 
    bool operator==(const Flower&) const = default;
	12. Use of projecctions, note we passed function address of size()
		std::ranges::sort(names, std::less<>{}, &std::string::size);
	13. difference std::pair vs std::tie, pair is for 2 values and tie is generalisation
	14. Algorithms require move operators not to throw,  noexcept
	15. std::ranges::subrange{first, sentinel};
	16. The constrained algorithms under std::ranges introduced with C++20 offer some benefits over the iterator-based algorithms under std
	17. std::nth_element, return nth element in provided range [bein, end), works on only sorted range, return nth element in sorted list, if not sorted then sort until nth element
	18.  std::partial_sort(), sort the element in provided range. std::partial_sort(v.begin(), left, right);
	19. Loop unrolling
	
		template <typename It, typename Value>
		auto find_fast(It first, It last, const Value& value) {
		  // Main loop unrolled into chunks of four
		  auto num_trips = (last - first) / 4;
		  for (auto trip_count = num_trips; trip_count > 0; --trip_count) {
			if (*first == value) {return first;} ++first;
			if (*first == value) {return first;} ++first;
			if (*first == value) {return first;} ++first;
			if (*first == value) {return first;} ++first;
		  }
		  // Handle the remaining elements
		  switch (last - first) {
			case 3: if (*first == value) {return first;} ++first;
			case 2: if (*first == value) {return first;} ++first;
			case 1: if (*first == value) {return first;} ++first;
			case 0:
			default: return last;
		  }
		}

6. Ranges and Views
	1. Views in the Ranges library are lazy evaluated iterations over a sequence.
	2. 
		auto squared_view = std::views::transform(numbers, square);
		for (auto s : squared_view) {  // The square lambda is invoked here
		  std::cout << s << " ";
		}
    The variable squared_view is not a copy of the numbers vector with the values squared; it is a proxy object for numbers with one slight difference—every time you access an element, the std::transform() function is invoked. This is why we say that a view is lazy evaluated.
	3. std::views::join(list_of_lists)
	4.  auto v1 = std::ranges::ref_view{s}; // Wrap container in a view
	5. The construction of a view is required to be a constant-time operation, O(1).
	6.  std::ranges::to<T>()
	7. std::ranges::copy
	8. std::ranges::sort, can be used only on actual container and cannot be used on another view;
	The filter view (and many other views) cannot preserve the iterator types of the underlying range, so cannot use with ranges::sort();
	
		auto vec = std::vector{4, 2, 7, 1, 2, 6, 1, 5};
		auto is_odd = [](auto i) { return i % 2 == 1; };
		auto odd_numbers = vec | std::views::filter(is_odd);

		std::ranges::sort(odd_numbers); // Doesn't compile
		std::ranges::sort(vec); //compile
		
	9. So, are there any views that can be sorted? Yes, an example would be std::views::take, which returns the first n elements in a range.
		auto vec = std::vector{4, 2, 7, 1, 2, 6, 1, 5};
		auto first_half = vec | std::views::take(vec.size() / 2);
		std::ranges::sort(first_half);
		
	10.  std::views::iota, which produces values within a half-open range.
	11. Sampling views
		  std::views::filter: 
		  std::views::take: Returns the n first elements of a range
		  std::views::drop: Returns all the remaining elements in a range after dropping the first n elements
	12.  std::views::drop_while([](auto i) { return i < 5; })
		 drop_while to discard values from the front that are less than 5
	13.  std::span, we can pass both built-in arrays or a container such as std::vector
	14.  std::ranges::common_view, common_view can be useful for working with legacy algorithms that expect the iterator and sentinel are of the same type.
	
7 Memory Management
	1.  If the memory page is not mapped in the main memory, a hardware exception occurs, and the page is loaded from disk into memory. This type of hardware exception is called a page fault. So page fault is hardware exception.
	2. Thrashing can happen when a system runs low on physical memory and is, therefore, constantly paging
	3. On Windows, the default stack size is usually set to 1 MB.
	4. instead of placement new, it is now possible to use some of the functions from <memory> whose names begin with std::uninitialized_ for constructing, copying, and moving objects to an uninitialized memory area.
	5.  And instead of calling the destructor explicitly, we can now use std::destroy_at()
		auto* memory = std::malloc(sizeof(User));
		auto* user_ptr = reinterpret_cast<User*>(memory);
		std::uninitialized_fill_n(user_ptr, 1, User{"john"});
		std::destroy_at(user_ptr);
		std::free(memory);
	6. Another replacement to placement new is std::construct_at
		C++20 also introduces std::construct_at(), which makes it possible to replace the std::uninitialized_fill_n() call with:
		std::construct_at(user_ptr, User{"john"});
	7. Note syntax
		auto operator new[](size_t size) -> void*
		auto operator delete[](void* p) noexcept -> void
	8. The CPU reads memory into its registers one word at a time. The word size is 64 bits on a 64-bit architecture, 32 bits on a 32-bit architecture, but cache read the bytes equivalent to cache line, i.e 64 bytes.
	9. If memory is not aligned then program will crash
	10.  if we want to write fully portable C++ code, we need to use std::align()
	11. std::align basically adjust the pointer by checking size requirement 
		
		bool is_aligned(void* ptr, std::size_t alignment) {
		  assert(ptr != nullptr);
		  assert(std::has_single_bit(alignment)); // Power of 2
		  auto s = std::numeric_limits<std::size_t>::max();
		  auto aligned_ptr = ptr;
		  std::align(alignment, 1, aligned_ptr, s);
		  return ptr == aligned_ptr;
		}
		
	12.  std::max_align_t, whose alignment requirement is at least as strict as all the scalar types
		auto* p = new char{}; 
		auto max_alignment = alignof(std::max_align_t);
		assert(is_aligned(p, max_alignment)); // True
	13. Both char are separate by std::max_align_t, it could be 16, 
		The space between p1 and p2 depends on the alignment requirements of std::max_align_t
		auto* p1 = new char{'a'};
		auto* p2 = new char{'b'};
	14. 
		assert(is_aligned(&x, 64));
		struct alignas(64) CacheLine {};
		alignas(64) int x{};
		alignas(64) int y{};
		// x and y will be placed on different cache lines
	15. C++17 introduced new overloads of operator new() and operator delete() which accept an alignment argument of type std::align_val_t. There is also an aligned_alloc()
	16.  The member with the largest alignment requirement also determines the alignment requirement for the entire data structure
	17. As a general rule, you can place the biggest data members at the beginning and the smallest members at the end. In this way, you can minimize the memory overhead caused by padding
	18. Weak pointer 
		if (auto shared_i = weak_i.lock())
	19. Note how the implementation of small buffer optimization structure in std::string
		which bit is used for indication of layout small or long
		union
		{
			struct
			{
				 char* Arr;
				 size_t Count;
				 size_t Capacity; // last bit indicator
			}Data;
			char Raw[24]; // last bit indicator
		};
		For heap-allocated strings, always set the upper and lower 8 bits of capacity to 0xFF. Again this gives you 48 bits to use for capacity information, which is more than enough. This has the advantage of working in any byte order.
	20. Building an arena
		1. Used when, Fixed size, Limited lifetime, single thread
		
		template <size_t N> 
		class Arena { 
		  static constexpr size_t alignment = alignof(std::max_align_t); 
		public: 
		  Arena() noexcept : ptr_(buffer_) {} 
		  Arena(const Arena&) = delete; 
		  Arena& operator=(const Arena&) = delete;
		   
		 
		  auto reset() noexcept { ptr_ = buffer_; } 
		  static constexpr auto size() noexcept { return N; } 
		  auto used() const noexcept {
			return static_cast<size_t>(ptr_ - buffer_); 
		  } 
		  auto allocate(size_t n) -> std::byte*; 
		  auto deallocate(std::byte* p, size_t n) noexcept -> void; 
		   
		private: 
		  static auto align_up(size_t n) noexcept -> size_t { 
			return (n + (alignment-1)) & ~(alignment-1); 
		  } 
		  auto pointer_in_buffer(const std::byte* p) const noexcept -> bool {
			return std::uintptr_t(p) >= std::uintptr_t(buffer_) &&
				   std::uintptr_t(p) < std::uintptr_t(buffer_) + N;
		  } 
		  alignas(alignment) std::byte buffer_[N]; 
		  std::byte* ptr_{}; 
		};
		
		
		template<size_t N> 
		auto Arena<N>::allocate(size_t n) -> std::byte* { 
		  const auto aligned_n = align_up(n); 
		  const auto available_bytes =  
			static_cast<decltype(aligned_n)>(buffer_ + N - ptr_); 
		  if (available_bytes >= aligned_n) { 
			auto* r = ptr_; 
			ptr_ += aligned_n; 
			return r; 
		  } 
		  return static_cast<std::byte*>(::operator new(n)); 
		}
		
		As a side note, relationally comparing raw pointers to disjoint objects is undefined behavior; this might be used by an optimizing compiler and result in surprising effects. To avoid this, we are casting the pointers to std::uintptr_t before comparing the addresses
		
		template<size_t N> 
		auto Arena<N>::deallocate(std::byte* p, size_t n) noexcept -> void { 
		  if (pointer_in_buffer(p)) { 
			n = align_up(n); 
			if (p + n == ptr_) { 
			  ptr_ = p; 
			} 
		  } 
		  else { 
			::operator delete(p);
		  }
		}
		 
	21. A custom memory allocator
		A minimal allocator in C++11 now looks like this:
			template<typename T> 
			struct Alloc {  
			    using value_type = T; 
			    Alloc(); 
			    template<typename U> Alloc(const Alloc<U>&); 
			    T* allocate(size_t n); 
			    auto deallocate(T*, size_t) const noexcept -> void; 
			}; 
			template<typename T> 
				auto operator==(const Alloc<T>&, const Alloc<T>&) -> bool;   
			template<typename T> 
				auto operator!=(const Alloc<T>&, const Alloc<T>&) -> bool;
	22.  std::allocator_traits
	23. Must requirements
		1. allocate, deallocate, ==, != 
	
		template <class T, size_t N> 
		struct ShortAlloc { 
		 
		  using value_type = T; 
		  using arena_type = Arena<N>; 
		  
		  // default copy move assignment == != removed from this to minimize the change
		  template <class U> struct rebind {
			using other = ShortAlloc<U, N>;
		  };
		  auto allocate(size_t n) -> T* {
			return reinterpret_cast<T*>(arena_->allocate(n*sizeof(T)));
		  }
		  auto deallocate(T* p, size_t n) noexcept -> void {
			arena_->deallocate(reinterpret_cast<std::byte*>(p), n*sizeof(T));
		  }

		  template <class U, size_t M> friend struct ShortAlloc;
		private:
		  arena_type* arena_;
		};
	24. Using polymorphic memory allocators,  <memory_resource> header
		1.  all standard containers under the namespace std::pmr use the same allocator, namely std::pmr::polymorphic_allocator
		2.  All memory resources derive from the base class std::pmr::memory_resource
		3. 3 types
			1. std::pmr::synchronized_pool_resource, thread safe
			2. std::pmr::monotonic_buffer_resource, simlar to Arena, variable size allcation memory
			3. std::pmr::unsynchronized_pool_resource :  fixed-size memory blocks, which avoids fragmentation within each pool.  not thread-safe.
		4. How to get allocator of different types
			std::pmr::new_delete_resource(): Uses the global operator new and operator delete.
			std::pmr::null_memory_resource(): A resource that always throws std::bad_alloc whenever it is asked to allocate memory.
			std::pmr::get_default_resource(): Returns a globally default memory resource that can be set at runtime by set_default_resource(). The initial default resource is new_delete_resource()
		5. Usage
				auto buffer = std::array<std::byte, 512>{};
				auto resource = std::pmr::monotonic_buffer_resource{
					buffer.data(), buffer.size(), std::pmr::new_delete_resource()};
				auto unique_numbers = std::pmr::set<int>{&resource};
		6. Implementing a custom memory resource, similar to shown in 24.3
			 We need to publicly inherit from std::pmr::memory_resource and then implement three pure virtual functions that will be invoked
			1. allocate, 2. deallocate, 3. do_is_equal
			
			class PrintingResource : public std::pmr::memory_resource {
			public:
			  PrintingResource() : res_{std::pmr::get_default_resource()} {}
			private:
			  void* do_allocate(std::size_t bytes, std::size_t alignment)override {
				std::cout << "allocate: " << bytes << '\n';
				return res_->allocate(bytes, alignment);
			  }
			  void do_deallocate(void* p, std::size_t bytes,
								 std::size_t alignment) override {
				std::cout << "deallocate: " << bytes << '\n';
				return res_->deallocate(p, bytes, alignment);
			  }
			  bool do_is_equal(const std::pmr::memory_resource& other) 
				const noexcept override {
				return (this == &other);
			  }
			  std::pmr::memory_resource* res_;  // Default resource
			};
			
			auto res = PrintingResource{};
			auto vec = std::pmr::vector<int>{&res};

8 Compile-Time Programming
	1. Remove, C V qualifier, decay also does same thing
		typename std::remove_cvref<decltype(v)>::type product{1};
	2. Type trait categories
		1.  return information about a type as a boolean
		2.  return a new type
	3. std::is_base_of<>::::value, std::is_floating_type<>::value, std::is_same<>::value, std::is_unsigned	
	4. All _v are replaced by ::value
	5. Transform types	
		std::remove_pointer_t<int*>;  // -> int
		std::add_pointer_t<float>;    // -> float*
	6. constexpr does not work on local static and thread_local
	7.  consteval
	8. if constexpr, eveluate at compile time used in SFINE
		if (std::is_floating_point_v<T>) { return std::fmod(v, n); }
		else { return v % n; }
	9.  % operator is used to get the modulus of integers, while std::fmod() is used for floating-point types.
	10. Constraints and concepts
		1. template <typename T>
			concept Number = FloatingPoint<T> || std::is_integral_v<T>;
					
			concept range = requires(T& t) {
			  ranges::begin(t);
			  ranges::end(t);
			};
			
			template <typename T>
			concept Point = requires(T p) {
			  requires std::is_same_v<decltype(p.x()), decltype(p.y())>;
			  requires Arithmetic<decltype(p.x())>;
			};
		2. Wherever typename is we can replace it with concept
		3.  std::equality_comparable,  std::totally_ordered,  std::moveable, std::copyable,  std::regular
		4. Example 1: creating a generic safe cast function
			1. ##IMP If casting between pointers with a static_cast(), we might get undefined behavior if the types aren't sharing a common base class.
			2.  we utilize the template function make_false<T>() to delay the generation until required.
		
			template <typename T> constexpr auto make_false() { return false; }
			template <typename Dst, typename Src> 
			auto safe_cast(const Src& v) -> Dst { 
			  using namespace std;
			  constexpr auto is_same_type = is_same_v<Src, Dst>;
			  constexpr auto is_pointer_to_pointer =  
				is_pointer_v<Src> && is_pointer_v<Dst>; 
			  constexpr auto is_float_to_float =  
				is_floating_point_v<Src> && is_floating_point_v<Dst>; 
			  constexpr auto is_number_to_number =  
				is_arithmetic_v<Src> && is_arithmetic_v<Dst>; 
			  constexpr auto is_intptr_to_ptr = 
				(is_same_v<uintptr_t,Src> || is_same_v<intptr_t,Src>)
				&& is_pointer_v<Dst>;
			  constexpr auto is_ptr_to_intptr =
				is_pointer_v<Src> &&
				(is_same_v<uintptr_t,Dst> || is_same_v<intptr_t,Dst>);
				
			  if constexpr(is_same_type) { 
				return v; 
			  }
			  else if constexpr(is_intptr_to_ptr || is_ptr_to_intptr){
				return reinterpret_cast<Dst>(v); 
			  } 
			  else if constexpr(is_pointer_to_pointer) { 
				assert(dynamic_cast<Dst>(v) != nullptr); 
				return static_cast<Dst>(v); 
			  } 
			  else if constexpr (is_float_to_float) { 
				auto casted = static_cast<Dst>(v); 
				auto casted_back = static_cast<Src>(v); 
				assert(!isnan(casted_back) && !isinf(casted_back)); 
				return casted; 
			  }  
			  else if constexpr (is_number_to_number) { 
				auto casted = static_cast<Dst>(v); 
				auto casted_back = static_cast<Src>(casted); 
				assert(casted == casted_back); 
				return casted; 
			  } 
			  else {
				static_assert(make_false<Src>(),"CastError");
				return Dst{}; // This can never happen, 
				// the static_assert should have failed 
			  }
			}
		5. Custom hash function
			1. we need this custom hash type having operator()
			struct hash<PrehashedString> {
			  constexpr auto operator()(const PrehashedString& s) const {
				return s.get_hash();
			  }
			};
			
			For custom class we only require operator ==, hashing is done in hash type
			operator ==
			
			For map we require only operator <()

9 Essential Utilities
	1.  Trying to access the value of an empty optional using operator*() or operator->() is undefined behavior. use has_value()
	2. Two empty optional values are considered equal. An empty optional is considered less than a non-empty.
	3. tuple expand to compiler generated struct. Accessing member  std::get<0>(t) 			
		// The Tuple class is generated first:
		class Tuple { 
		  int data0_{};
		  bool data1_{};
		public:
		  Tuple(int v0, bool v1) : data0_{v0}, data1_{v1} {} 
		};
		
		// get<0>(Tuple) is then generated to something like this:
		auto& get(const Tuple& tpl) { return data0_; }
	4. Iterating std::tuple members
		 Then, since the tuple contains different types, we need to write a meta-function that generates a new function for every type in the tuple.
		 
		template <size_t Index, typename Tuple, typename Func> 
		void tuple_at(const Tuple& t, Func f) {
		  const auto& v = std::get<Index>(t);
		  std::invoke(f, v);
		}

		auto t = std::tuple{1, true, std::string{"Jedi"}};
		auto f = [](const auto& v) { std::cout << v << " "; };
		tuple_at<0>(t, f);


		template <typename Tuple, typename Func, size_t Index = 0> 
		auto tuple_any_of(const Tuple& t, const Func& f) -> bool { 
		  constexpr auto n = std::tuple_size_v<Tuple>; 
		  if constexpr(Index < n) { 
			bool success = std::invoke(f, std::get<Index>(t)); 
			if (success) {
			  return true;
			}
			return tuple_any_of<Tuple, Func, Index+1>(t, f); 
		  } else { 
			return false; 
		  } 
		}
	5. std::tie(), returns tuple
	6. 
		template<typename ...Ts> 
		auto f(Ts... values) {
		  g(values...);
		}

		Ts is a list of types
		<typename ...Ts> indicates that the function deals with a list
		values... expands the pack such that a comma is added between every value
	7. Dynamically sized heterogenous collections
		1.  std::any uses heap allocation, NOTE: it is not fixed size, can grow to any number
			auto container = std::vector<std::any>{42, "hi", true};
			if (a.type() == typeid(int)) {
			const auto& value = std::any_cast<int>(a);
		2. std::varient uses stack, its like union
			std::variant works in a somewhat similar manner to a tuple, except that it only stores one object at a time
			std::variant is typically the size of the biggest alternative, plus the size of the index.
			It store the index to idetify type
			
			using VariantType = std::variant<int, std::string, bool>; 
			VariantType v{}; 
			std::holds_alternative<int>(v);  // true, int is first alternative
			v = 7; 
			std::holds_alternative<int>(v);  // true
			
			if (var.valueless_by_exception()) {  // to check the value is present or not
		3. Visiting varient
			in C++17
			
			template<class... Lambdas>
			struct Overloaded : Lambdas... {
			  using Lambdas::operator()...;
			};
			
			In c++20
			template<class... Lambdas> 
			Overloaded(Lambdas...) -> Overloaded<Lambdas...>;
		4.  There are two ways to instantiate std::get(), with an index or with a type:
		5. Example 1: projections and comparison operators

10 Proxy Objects and Lazy Evaluation
	1.  bool operator==(const LengthProxy& other) const = default; 
		auto operator<=>(const LengthProxy& other) const = default;
		we require this much only for <=>
11 Concurrency
	1. std::thread::hardware_concurrency, 
    2. std::jthread  
		void print(std::stop_token stoken)  // compiler passes stop_token values in parameter value
		while (!stoken.stop_requested());
		
		auto joinable_thread = std::jthread(print); // here we have not passed explicitly value of stop_token as argument
		joinable_thread.request_stop();
	3.  std::scoped_lock vs std::lock_guard
		std::scoped_lock use deadlock prevention algo, can be used with std::lock
	4. cv.wait(lock); // The lock is released while waiting 
		wait() also unlocks the mutex while sleeping and then acquires the mutex before it returns.
		wait is over means it enter in critical section, so acquires lock
	5.  std::counting_semaphore, std::barrier, and std::latch,  std::binary_semaphore
	6.  auto p = std::promise<int>{}; 
		std::thread(divide, 45, 5, std::ref(p)).detach();
		 
		p.set_exception(std::make_exception_ptr(e));
		p.set_value();
		
		auto f = p.get_future();
		f.get();
	7. auto task = std::packaged_task<decltype(divide)>{divide}; 
		auto f = task.get_future();
		std::packaged_task is itself a callable object that can be moved to the std::thread
	8.  std::async();
		const auto& result = future.get();
		sometimes delayed execution until future.get() is called
	9. Using latches
		1.  auto lat = std::latch{8};
			lat.count_down(); // Decrement but don't wait
			if (lat.try_wait())
			lat.wait();
			lat.arrive_and_wait(); // Decrement and block while not zero
		2. When a thread is created, a contiguous block of memory is allocated for the stack. Typically, this memory does not yet reside in physical memory when it is first allocated in the virtual address space. Instead, when the stack is being used, page faults will be generated in order to map the virtual memory to physical memory
		3.  The stack memory is unlikely to be paged out by the operating system, so it is usually enough to run some code that will generate page faults and thereby map the virtual stack memory to physical memory. This process is called prefaulting
		4. cannot be resued
	10. Using barriers
		1.  when the internal counter of the barrier reaches zero) two things happens:
			The completion function provided to the constructor is called by the barrier.
			The internal counter is reset to its initial value after the completion function has returned.
		2. we can declare, 
			  static thread_local auto engine = 
				std::default_random_engine{std::random_device{}()};
			  auto dist = std::uniform_int_distribution<>{min, max};
			  return dist(engine);
		3. auto bar = std::barrier{n, check_result};
			bar.arrive_and_wait();       // Join
	11. Semaphore
		std::counting_semaphore<4> sem_{4};
		sem_.acquire(); -- , blocks when it is 0
		sem_.release(); ++ , inc and then send notification to acquire thread.
		 without blocking using the try_acquire(),  try_acquire_for() and try_acquire_until()
	12. std::binary_semaphore = std::counting_semaphore<1>;
	13. Having virtual function disqualify for trivallay copyable 
		static_assert(std::atomic<int>::is_always_lock_free);
	14. An atomic type that is guaranteed to always be lock-free is std::atomic_flag
	15. Fortunately, C++20 added a wait and notify API to std::atomic
	16. in shared pointer only ref counting mechanism is thread safe
	17.  std::shared_ptr (introduced in C++20
	18.  std::atomic_ref was introduced in C++20.
	19. Memeory Model
		1. When acquiring a mutex, we are creating an acquire memory fence. It tells the system that no memory accesses (reads or writes) can be moved above the line where the acquire fence is located.
		2. reference counter in a std::shared_ptr uses a relaxed model when incrementing the counter (but not when decrementing the counter).
		3. A good way of controlling the number of threads is to use a thread pool that can be sized to match the current hardware.
		4. Thread priorities are important for lowering the latency of tasks.
	20. One phenomenon related to thread priorities that can hurt the performance, and should be avoided, is called priority inversion. It happens when a thread with high priority is waiting to acquire a lock that is currently held by a low-priority thread. Such dependencies hurt the high-priority thread, which is blocked until the next time the low-priority thread gets scheduled so that it can release the lock.
	21. 
		#include <pthreads> // Non-portable header 
		auto set_affinity(const std::thread& t, int cpu) {
		  cpu_set_t cpuset;
		  CPU_ZERO(&cpuset);
		  CPU_SET(cpu, &cpuset);
		  pthread_t native_thread = t.native_handle(); 
		  pthread_set_affinity(native_thread, sizeof(cpu_set_t), &cpuset); 
		}
	22.  std::hardware_destructive_interference_size
	
		struct alignas(std::hardware_destructive_interference_size) Element {
		   int counter_{};
		};
	23. std::atomic_flag::test_and_set : Atomically changes the state of a std::atomic_flag to set (true) and returns the value it held before.

12 Coroutines and Lazy Generators
	1. Instead of blocking, co_await suspends the execution until it gets resumed and the asynchronous read and write functions have completed
	2. fibers are stack based coroutine or called as light weight threads in java
	3. In summary, stackful coroutines demand a big initial memory allocation for the coroutine frame and the side stack, or need to support a growing stack. Stackless coroutines only  need to allocate memory for the coroutine frame.
	4.  Switching between coroutines is substantially faster than switching between processes and OS threads
	5.  stackful coroutine has a more expensive context switch operation since it has more information to save and restore during suspend and resume compared to a stackless coroutine.
	6.  The stackless coroutines in C++20 were designed with the following goals:
		1. Add very little memory overhead. This makes it possible to have many more coroutines alive
		2. Efficient context switching
		3. Highly flexible. C++ coroutines have more than 15 customization points,
		4. Do not require C++ exceptions to handle errors. This means that you can use coroutines in environments where exceptions are turned off.
	7. co_await: co_yield: co_return std::coroutine_handle std::suspend_never: std::suspend_always:
      std::coroutine_traits
	8. A C++ function is a coroutine if it contains any of the keywords co_await, co_yield, or co_return
	9. Four components, 
		1. main -> it will have generator<promise> obj, and it will call a method from generator class
		2. coroutine defination -> return generator<promise>, has co_wait/co_return/co_yield
		3. generator class -> has std::coroutine_handle<Promise> h_, 
		4. promise struct -> has 5 compulsory methods
	10.  promise_type = Promise, compiler needs it to generate code.
	11. 
		struct Promise {
		  auto get_return_object() { return Resumable{*this}; }
		  auto initial_suspend() { return std::suspend_always{}; }
		  auto final_suspend() noexcept { return std::suspend_always{}; }
		  void return_void() {}
		  void unhandled_exception() { std::terminate(); }
		};
	12.  std::suspend_never
		struct std::suspend_always {
		  constexpr bool await_ready() const noexcept { return false; }
		  constexpr void await_suspend(coroutine_handle<>) const noexcept {}
		  constexpr void await_resume() const noexcept {}
		};
		
		auto coroutine() -> Resumable {       
			std::cout << i_++ << " ";         
			co_await std::suspend_always{};
			std::cout << i_++ << " ";
		}
	13.  It's also possible to create coroutines using lambda expressions by inserting co_await, co_return, and/or co_yield in the body of a lambda.
	14. Some usages of lambdas make it really easy to accidentally destruct the function object before the coroutine frame is destroyed. For example, by using an immediately invoked lambda, we can easily get into trouble:
		
		auto coro = [i = 0]() mutable -> Resumable { 
		  std::cout << i++; 
		  co_await std::suspend_always{};
		  std::cout << i++;
		}();               // Invoke lambda immediately
		coro.resume();     // Undefined behavior! Function object
		coro.resume();     // already destructed
		
		auto coro = LambdaType{}(); // Invoke operator() on temporary object
		coro.resume();              // Ops! Undefined behavior
	15. get from  std::current_exception() set in unhandled_exception() 
	16. std::lerp(start, stop, amount), which computes the linear interpolation between two values with a specified amount.

13 Asynchronous Programming with Coroutines --> skipped
	1. await_ready() returns a bool that indicates whether the result is ready

14 Parallel Algorithms
	1. Divide and conquer
		We will here implement another version of a parallel transform algorithm using divide and conquer. It works as follows: if the input range is smaller than a specified threshold, the range is processed; otherwise, the range is split into two parts:
			The first part is processed on a newly branched task
			The other part is recursively processed at the calling thread
	2. Example implementation of parallel transform
		
		template <typename SrcIt, typename DstIt, typename Func>
		auto par_transform(SrcIt first, SrcIt last, DstIt dst,
						   Func func, size_t chunk_sz) {
		  const auto n = static_cast<size_t>(std::distance(first, last));
		  if (n <= chunk_sz) {
			std::transform(first, last, dst, func); // this is where actual operation happening, rest is diving the task into multiple chunks and collecting result at last
			return;
		  }
		  const auto src_middle = std::next(first, n / 2);
		  // Branch of first part to another task
		  auto future = std::async(std::launch::async, [=, &func] {
			par_transform(first, src_middle, dst, func, chunk_sz);
		  });
		  // Recursively handle the second part
		  const auto dst_middle = std::next(dst, n / 2);
		  par_transform(src_middle, last, dst_middle, func, chunk_sz);
		  future.wait(); 
		}
	3. Implementing parallel std::count_if(), it is conditional count
		same as par_transform, except  std::count_if(first, last, pred);
	4. Implementing parallel std::copy_if() : parallel copy from source to destination, if condition matches then only
		1.  we immediately run into problems as we cannot write to the destination iterator concurrently. with the above arroach, it is a failed attempt with undefined behavior, since both tasks will write to the same position in the destination range:
		
			Approach 1: Use a synchronized write position
				i.e using  auto dst_write_idx = std::atomic_size_t{0};
				but it cause false sharing and trashing
			Approach 2: 
				1. make chunk for each thread, each thread will copy in its range only.
				2. when all thread finish, there will be empty blocks in each range where element did not match and skipped to copy, so now we have to squash the range.  Move the sparse range sequentially into a continuous range. use 2 pointer method.
	5. Unsequenced policy
		The unsequenced policy was added in C++20. It tells the algorithm that the loop is allowed to be vectorized using, for example, SIMD instructions. In practice, this means that you cannot use any synchronization primitives in the code you pass to the algorithm, since this could result in deadlocks.
		
		auto v = std::vector<std::string>{"Ada", "APL" /* ... */ };
		auto tot_size = size_t{0};
		auto mut = std::mutex{};
		std::for_each(std::execution::par, v.begin(), v.end(),
					  [&](const auto& s) { 
			auto lock = std::scoped_lock{mut}; // Lock
			tot_size += s.size(); 
		  }                                    // Unlock
		);
		
		This code is now safe to execute using std::execution::par, but it is very inefficient. If we were to change the execution policy to std::execution::unseq, the result would not only be an inefficient program but also a program that runs the risk of deadlocking!
		The unsequenced execution policy tells the algorithm that it may reorder the instruction of our code in a way that is normally not allowed by the optimizing compiler.
	6. std::transform_reduce()
		As an addition to the standard library algorithms, std::transform_reduce() has also been added to the <numeric> header. It does exactly what it says: it transforms a range of elements as std::transform() and then applies a function object. This accumulates them out of order, like std::reduce():
			auto v = std::vector<std::string>{"Ada","Bash","C++"}; 
			auto num_chars = std::transform_reduce( 
			  v.begin(), v.end(), size_t{0}, 
			  [](size_t a, size_t b) { return a + b; },     // Reduce
			  [](const std::string& s) { return s.size(); } // Transform 
			); 
			// num_chars is 10
	7. Executing algorithms on the GPU
		 However, the parallel execution policies std::execution::par and std::execution::par_unseq allow compilers to move the execution of standard algorithms from the CPU to the GPU. One example of this is NVC++, the NVIDIA HPC compiler. It can be configured to compile standard C++ algorithms for execution on NVIDIA GPUs.
	8. std::reduce is parallel version of std::accumulate
		const std::array<int, 3> a{ 1, 2, 3 };
		//The default binary operation is std::plus with an initial value of 0.
		std::reduce(std::cbegin(a), std::cend(a)); // == 6
		// Using a custom binary op:
		std::reduce(std::cbegin(a), std::cend(a), 1, std::multiplies<>{}); // == 6